import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import scraperRoutes from './routes/scraper.js';
import { getCompaniesToScrape, updateCompanyLastScrape, saveMedications, publishChanges } from './services/hubspotService.js';
import { findPipelineUrls } from './services/searchService.js';
import { smartScrape } from './services/playwrightService.js';
import { scrapeWebsite } from './services/scraperService.js';
import { extractPipelineData } from './services/openaiService.js';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());

// Routes
app.use('/api/scraper', scraperRoutes);

app.get('/', (req, res) => {
  res.json({ message: 'Pharma Pipeline Scraper API' });
});

// FunciÃ³n de scraping automÃ¡tico
async function runAutomaticScraping() {
  try {
    console.log('\nğŸ¤– ========================================');
    console.log('ğŸ¤– INICIANDO SCRAPING AUTOMÃTICO');
    console.log('ğŸ¤– ========================================\n');
    
    // 1. Obtener empresas que necesitan scraping (>3 meses)
    const companies = await getCompaniesToScrape();
    
    if (companies.length === 0) {
      console.log('âš ï¸  No hay empresas para procesar (todas fueron scrapeadas recientemente)');
      return;
    }
    
    console.log(`\nğŸ“‹ Procesando ${companies.length} empresa(s)...\n`);
    
    // 2. Procesar cada empresa
    for (const company of companies) {
      console.log(`\nğŸ¢ ======== Procesando: ${company.name} ========`);
      
      const companyMedications = [];
      
      try {
        // Buscar URLs
        const links = await findPipelineUrls(company.name);
        
        if (!links || links.length === 0) {
          console.log(`  âš ï¸  No se encontraron URLs para ${company.name}`);
          continue;
        }
        
        console.log(`  âœ… Encontradas ${links.length} URLs`);
        
        // Procesar URLs
        let successfulScrapes = 0;
        const maxSuccessful = 5;
        
        for (const link of links) {
          if (successfulScrapes >= maxSuccessful) break;
          
          console.log(`\n  ğŸŒ Probando: ${link}`);
          
          try {
            const content = await smartScrape(link, scrapeWebsite);
            
            if (content.length < 100) {
              console.log(`  âš ï¸  Contenido muy corto, saltando...`);
              continue;
            }
            
            console.log(`  ğŸ“„ Contenido: ${content.length} caracteres`);
            console.log(`  ğŸ¤– Extrayendo datos con OpenAI...`);
            
            const pipelineData = await extractPipelineData(content, link);
            
            if (pipelineData.productos && pipelineData.productos.length > 0) {
              // Agregar nombre de empresa a cada medicamento
              const medicationsWithCompany = pipelineData.productos.map(med => ({
                ...med,
                empresa: company.name
              }));
              
              companyMedications.push(...medicationsWithCompany);
              successfulScrapes++;
              console.log(`  âœ… ${pipelineData.productos.length} medicamentos extraÃ­dos (${successfulScrapes}/${maxSuccessful})`);
            } else {
              console.log(`  â„¹ï¸  No se encontraron medicamentos`);
            }
            
          } catch (error) {
            console.error(`  âŒ Error: ${error.message}`);
          }
        }
        
        // 3. Guardar medicamentos de esta empresa
        if (companyMedications.length > 0) {
          console.log(`\n  ğŸ’¾ Guardando ${companyMedications.length} medicamentos de ${company.name}...`);
          
          await saveMedications(companyMedications);
          await publishChanges();
          console.log(`  âœ… Medicamentos guardados en HubSpot`);
        }
        
        // 4. Actualizar fecha de Ãºltimo scraping
        await updateCompanyLastScrape(company.id);
        console.log(`  ğŸ“… Fecha de scraping actualizada`);
        
      } catch (error) {
        console.error(`âŒ Error procesando ${company.name}: ${error.message}`);
      }
    }
    
    console.log('\nğŸ‰ ========================================');
    console.log('ğŸ‰ SCRAPING AUTOMÃTICO COMPLETADO');
    console.log('ğŸ‰ ========================================\n');
    
  } catch (error) {
    console.error(`\nâŒ Error en scraping automÃ¡tico: ${error.message}`);
  }
}

app.listen(PORT, async () => {
  console.log(`ğŸš€ Server running on port ${PORT}`);
  
  // Iniciar scraping automÃ¡tico despuÃ©s de que el servidor estÃ© listo
  console.log('â³ Esperando 5 segundos antes de iniciar scraping automÃ¡tico...');
  setTimeout(async () => {
    await runAutomaticScraping();
  }, 5000); // Esperar 5 segundos para que el servidor estÃ© completamente listo
});

